#!/usr/bin/python3

import configparser
import os
import sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import argparse

from binaryaudit import util
from binaryaudit import abicheck
from binaryaudit import cli
from binaryaudit.orchestrator import ba_orchestrator as orchestrator
from binaryaudit import dnf
from binaryaudit.cli import arg_parser, arg_parser_rpm

args = cli.arg_parser.parse_args()

util.set_verbosity(args.verbose)

if None is args.cmd:
    if not None is args.is_elf:
        if abicheck.is_elf(args.is_elf):
            util.note("'{}' is an ELF binary".format(args.is_elf))
            sys.exit(0)
        util.note("'{}' is not an ELF binary".format(args.is_elf))
        sys.exit(3)

    cli.arg_parser.print_help()
elif "rpm" == args.cmd:
    rpm_binaryaudit = None
    if 'y' == args.enable_telemetry:
        try:
            cli.validate_telemetry_args(args)
        except argparse.ArgumentError as e:
            util.fatal(str(e))
            sys.exit(3)

    rpm_binaryaudit = orchestrator(
            args.product_name,
            args.derivative,
            args.build_id,
            args.enable_telemetry,
            util.logger,
            args.db_config
    )
    rpm_binaryaudit.get_product_id()
    rpm_binaryaudit.perform_binary_audit(args.buildurl, args.logurl)

    # Next call should be to perform the rpm package binary audit
    # That needs to be defined as part of ba_orchestrator class

    if args.list:
        if None is args.source_dir or None is args.out_filename:
            util.error("Pass package directory and JSON output file")
            sys.exit(1)
        abicheck.generate_package_json(args.source_dir, args.out_filename)
elif "db" == args.cmd:
    from binaryaudit.db import wrapper as db_wrapper
    try:
        db_conn = db_wrapper(args.db_config, util.logger)
        db_conn.initialize_db()
    except Exception as e:
        util.error(str(e))

    if args.check_connection:
        if db_conn.is_db_connected:
            util.note("Connection successful")
            sys.exit(0)
        else:
            util.note("Connection unsuccessful")
            sys.exit(1)

elif "poky" == args.cmd:
    from binaryaudit import poky
    from binaryaudit.db import TRANSACTION_MAIN_RESULT_FAILED, TRANSACTION_MAIN_RESULT_PASSED, TRANSACTION_MAIN_RESULT_PENDING

    db_conn = None
    if 'y' == args.enable_telemetry:
        try:
            cli.validate_telemetry_args(args)
        except argparse.ArgumentError as e:
            util.fatal(str(e))
            sys.exit(3)

        from binaryaudit.db import wrapper as db_wrapper
        try:
            db_conn = db_wrapper(args.db_config, util.logger)
            db_conn.initialize_db()
        except Exception as e:
            util.error(str(e))

    if args.compare_buildhistory:
        suppr = []  # TODO add suppression option
        d1 = args.buildhistory_baseline
        d2 = args.buildhistory_current

        if not os.path.isdir(d1) and not 'y' == args.enable_telemetry:
                util.warn("Directory '{}' doesn't exist.".format(d1))
                sys.exit(1)
        # Either need the baseline directory passed or telemetry enabled
        # to fetch the baseline.
        if not os.path.isdir(d2):
                util.warn("Directory '{}' doesn't exist.".format(d2))
                sys.exit(1)

        if 'y' == args.enable_telemetry:
            prod_id = db_conn.get_product_id(args.product_name, args.derivative)
            if not prod_id:
                util.error("Couldn't find a matching product ID.")
                sys.exti(1)
            util.debug("product_id: '{}'".format(prod_id))

            if d1:
                util.warn("Telemetry is enabled, ignoring the supplied buildhistory baseline.")
            baseline_id, d1 = poky.retrieve_baseline(db_conn, prod_id)
            if not baseline_id or not d1:
                sys.exit(1)

            db_conn.insert_main_transaction(args.build_id, prod_id, args.buildurl,
                                            args.logurl, TRANSACTION_MAIN_RESULT_PENDING, baseline_id)

        build_ret_acc = abicheck.DIFF_OK
        build_result = TRANSACTION_MAIN_RESULT_PASSED

        import glob
        # Only iterate through packages for now.
        # Only iterate through d2 now. Reverse iteration might bake sense, too.
        for fn in glob.glob(d2 + "/packages/*/*/binaryaudit", recursive=False):
            item_name, base_version, new_version, exec_time, result, res_details, ret_acc = poky.recipe_abicheck(fn, d1, d2, suppr)

            # Set the build accumulated value to the highest found score.
            if ret_acc > build_ret_acc:
                build_ret_acc = ret_acc

            util.debug("item: '{}', base: '{}', new: '{}', duration: '{}', res: '{}'".format(item_name, base_version, new_version, exec_time, result))

            if 'y' == args.enable_telemetry:
                db_conn.insert_ba_transaction_details(args.build_id, item_name, base_version, new_version, exec_time, result, res_details)

        if 'y' == args.enable_telemetry:
            if abicheck.DIFF_OK != build_ret_acc:
                build_result = TRANSACTION_MAIN_RESULT_FAILED
            db_conn.update_ba_test_result(args.build_id, build_result)
    elif args.insert_baseline:
        if not 'n' == args.enable_telemetry:
            # Another way would be to implicitly enable telemetry
            util.error("Telemetry is not anabled")
            sys.exit(1)

        product_id = db_conn.get_product_id(args.product_name, args.derivative)

        db_conn.insert_main_transaction(args.build_id, product_id, args.buildurl, args.logurl, TRANSACTION_MAIN_RESULT_PASSED)

        data = None
        with open(args.insert_baseline, "rb") as f:
            data = f.read()
            f.close
        db_conn.insert_ba_baseline_data(args.build_id, product_id, data)
elif "mariner" == args.cmd:
    config = configparser.ConfigParser()
    config.read('../conf/binaryaudit.conf')
    new_json_file = config['Mariner']['new_json_file_name']
    old_json_file = config['Mariner']['old_json_file_name']
    abicheck.generate_package_json(args.input_dir, new_json_file, args.debug)
    dnf.download(args.input_dir, new_json_file, old_json_file, args.debug)

else:
    # This should be caught by argparse anyway
    raise("Unknown command '{}'".format(args.cmd))
